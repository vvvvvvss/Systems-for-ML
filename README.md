# Systems for Machine Learning

On the 13th, 14th and 15th of June, 2025, we had an exceptional experience at the *Systems for Machine Learning* workshop conducted by the ACM student chapter of IISc Bengaluru. With an overhwelming inflow of Machine Learning and Deep learning models we often forget to learn or understand what's under the hood. This workshop explored exactly that. Nine sessions, one panel discussion, one live demo and one hands-on project across three days and here's what was covered.

## Session 1 : Edge AI for Advanced Automobile In-Cabin Experience
***Keynote speaker - Dr. Amod Anandkumar, HARMAN Automotive***  
This session explored how megatrends like connectivity, autonomy, and electric mobility are reshaping the automotive industry. Focused on in-cabin experiences, the talk highlighted how AI-powered screens, passenger displays, and rearview systems enhance user interaction through continuous updates and upgrades. It introduced the concept of the **Software Defined Vehicle (SDV)**, where applications run over middleware, hardware abstraction layers, and hardware. The session also traced the evolution from distributed controllers to domain and zonal controllers. Challenges like brand consistency and opportunities for AI-driven personalization in multi-screen environments were emphasized.

## Session 2 : Introduction & Overview: Systems in ML
***Speaker - Divij Ghose***  
Session 2 focused on the TensorFlow ecosystem and hardware accelerators for ML. It began with TensorFlow Lite, a lightweight ML framework for mobile and embedded devices, and TensorFlow Serving for production deployment. The session covered transfer learning techniques and model optimization strategies for efficient inference. Specialized hardware like GPUs and TPUs was introduced, emphasizing their parallelism and architecture suited for ML workloads. TPUs, developed by Google, were highlighted for their speed, integration, and limitations like high cost and limited scalability. Key challenges discussed included latency, energy efficiency, and the need for accessible, distributed frameworks for large-scale parallelism.

## Session 3 : Edge Computing - Deploying ML on the Go
***Keynote speakers - Alka and Anusha, Harman*** 
Session 3 focuses on model conversion and deployment for edge computing environments. The presentation showcases various deployment format examples including framework-specific tools like LiteRT (TensorFlow Lite) for ARM processors and mobile acceleration, ONNX Runtime for cross-platform deployment, and hardware-specific SDKs like Qualcomm Neural Processing SDK for optimized inference. Additional tools covered include PyTorch ExecutorTorch for mobile deployment, TVM for tensor compilation, and OpenVINO for Intel hardware optimization. The session emphasizes converting trained models into efficient formats suitable for resource-constrained edge devices while maintaining performance across different hardware platforms and architectures. 

## Session 4 : Spiking Neural Networks For Engergy Efficient And Fault Tolerant Neuromorphic Computing
***Keynote speaker - Dr. Gopalakrishnan Srinivasan, IIT Madras***  
Spiking Neural Networks (SNNs) are biologically-inspired computing models that offer energy-efficient and fault-tolerant neuromorphic systems. Unlike traditional ANNs that continuously process data, SNNs generate spikes when neurons are excited, enabling energy efficiency through rate encoding or temporal coding. Their biological design eliminates multipliers, using binary accumulators instead. Key research areas include ANN-to-SNN conversion by replacing activation functions like ReLU with spiking equivalents, and knowledge distillation to transfer complex ANN knowledge to efficient SNNs. Emerging directions encompass federated learning, hardware-aware compression, on-device learning, and adversarial security, aiming to develop robust neuromorphic frameworks for resource-constrained edge devices.

## Session 5 : Software & Profiler Basics for ML 
***Keynote speaker - Sunny Manchanda, DRDO***

## Session 6 : Case Study & Lab: Accelerating ML Workloads 
***Speaker - Kautuk and Mayank, IISc***

## Session 7 : Foundational Models as OS
***Keynote speaker - Dr. Suparna Bhattacharya, HPE***
Session 7 explores the concept of treating foundational models as operating systems, featuring research on AIOS (LLM Agent Operating System). The presentation covers OS-inspired techniques including context switching across LLM agents, privilege modes for security with hierarchical instruction levels, and circuit breaking mechanisms for alignment and robustness. Key components include the AIOS agent ecosystem with SDK integration, agentic memory (A-Mem) for dynamic long-term memory organization, and drawing inspiration from traditional operating systems to design foundation model systems. The session demonstrates how OS principles can enhance LLM agent management and operational efficiency.

## Session 8 : Distributed ML - Getting Started 
**Speaker - *Dhruv Garg, Georgia Tech***

## Session 9 : Ensuring Reliability â€“ Scalability & Fault Tolerance
***Keynote speaker - Dibjajyothi & Dhanya Matthew***

## Panel Discussion
**Topic: Do We Need More Models or Better Systems for AI Breakthroughs?**
***Moderator: Dr. Kalapriya Kannan (Intuit)***
***Speakers: Dr. Anjaly Parayil (Microsoft), Dr. Sriparna Saha (IIT Patna), Anchal Gupta(NVIDIA), Dr. Sumit Kumar Mandal (IISc Bangalore), Dr. Praveen Jayachandran (IBM Research)***

## Live Demo : NVIDIA Autonomous Vehicles demo

## Hands-on Project
**Topic : Federated Learning**
