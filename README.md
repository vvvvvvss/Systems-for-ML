# Systems for Machine Learning

On the 13th, 14th and 15th of June, 2025, we had an exceptional experience at the *Systems for Machine Learning* workshop conducted by the ACM student chapter of IISc Bengaluru. With an overhwelming inflow of Machine Learning and Deep learning models we often forget to learn or understand what's under the hood. This workshop explored exactly that. Nine sessions, one panel discussion, one live demo and one hands-on project across three days and here's what was covered.

## Session 1 : Edge AI for Advanced Automobile In-Cabin Experience
***Keynote speaker - Dr. Amod Anandkumar, HARMAN Automotive***
This session explored how megatrends like connectivity, autonomy, and electric mobility are reshaping the automotive industry. Focused on in-cabin experiences, the talk highlighted how AI-powered screens, passenger displays, and rearview systems enhance user interaction through continuous updates and upgrades. It introduced the concept of the **Software Defined Vehicle (SDV)**, where applications run over middleware, hardware abstraction layers, and hardware. The session also traced the evolution from distributed controllers to domain and zonal controllers. Challenges like brand consistency and opportunities for AI-driven personalization in multi-screen environments were emphasized.


## Session 2 : Introduction & Overview: Systems in ML
***Speaker - Divij Ghose***
Session 2 focused on the TensorFlow ecosystem and hardware accelerators for ML. It began with TensorFlow Lite, a lightweight ML framework for mobile and embedded devices, and TensorFlow Serving for production deployment. The session covered transfer learning techniques and model optimization strategies for efficient inference. Specialized hardware like GPUs and TPUs was introduced, emphasizing their parallelism and architecture suited for ML workloads. TPUs, developed by Google, were highlighted for their speed, integration, and limitations like high cost and limited scalability. Key challenges discussed included latency, energy efficiency, and the need for accessible, distributed frameworks for large-scale parallelism.


## Session 3 : Edge Computing - Deploying ML on the Go
***Keynote speakers - Alka and Anusha, Harman***


## Session 4 : Spiking Neural Networks For Engergy Efficient And Fault Tolerant Neuromorphic Computing
***Keynote speaker - Dr. Gopalakrishnan Srinivasan, IIT Madras***
Spiking Neural Networks (SNNs) are a biologically inspired computing model used for energy-efficient and fault-tolerant neuromorphic systems. Unlike traditional artificial neural networks (ANNs) that continuously process data, SNNs introduce spikes when a neuron is excited, making them more energy-efficient. This spiking behavior allows information to be encoded either through rate encoding, which accesses input intensity, or temporal coding, where information is encoded in sparse, time-dependent spikes that lead to high performance after adequate training. The biological neuron model of SNNs eliminates the need for multipliers in matrix multiplications, replacing them with binary accumulators. A core area of research in this field is the conversion of ANN models to SNNs through techniques like ANN-to-SNN conversion, which involves replacing activation functions such as ReLU with spiking equivalents and adjusting for firing thresholds. Additionally, knowledge distillation is used to transfer the knowledge from a larger, more complex ANN model to a smaller, efficient SNN by mimicking its output distributions at controlled temperatures. Emerging research directions include federated learning, hardware-aware neural network compression, on-device learning, and secure inference against adversarial attacks on deep neural networks. The overarching goal is to develop robust neuromorphic computing frameworks that can perform complex AI tasks on resource-constrained edge devices, ensuring fault tolerance, security, and efficient power usage.



## Session 5 : Software & Profiler Basics for ML 
***Keynote speaker - Sunny Manchanda, DRDO***

## Session 6 : Case Study & Lab: Accelerating ML Workloads 
***Speaker - Kautuk and Mayank, IISc***

## Session 7 : Foundational Models as OS
***Keynote speaker - Dr. Suparna Bhattacharya, HPE***

## Session 8 : Distributed ML - Getting Started 
**Speaker - *Dhruv Garg, Georgia Tech***

## Session 9 : Ensuring Reliability â€“ Scalability & Fault Tolerance
***Keynote speaker - Dibjajyothi & Dhanya Matthew***

## Panel Discussion
**Topic: Do We Need More Models or Better Systems for AI Breakthroughs?**
***Moderator: Dr. Kalapriya Kannan (Intuit)***
***Speakers: Dr. Anjaly Parayil (Microsoft), Dr. Sriparna Saha (IIT Patna), Anchal Gupta(NVIDIA), Dr. Sumit Kumar Mandal (IISc Bangalore), Dr. Praveen Jayachandran (IBM Research)***

## Live Demo : NVIDIA Autonomous Vehicles demo

## Hands-on Project
**Topic : Federated Learning**
